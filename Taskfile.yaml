version: 3

run: once

vars:
  GIT_ROOT:
    sh: git -C "{{.TASKFILE_DIR}}" rev-parse --show-toplevel

  # Note that cluster name is also set in the k3d config file.
  K3D_CLUSTER_NAME: '{{default "aok" (env "K3D_CLUSTER_NAME")}}'
  KUBECTL_CONTEXT: k3d-{{.K3D_CLUSTER_NAME}}

  SCRIPT_TMP_DIR: '{{joinPath .GIT_ROOT "scripts/tmp"}}'

  REGISTRY_BASE: ghcr.io/jlucktay
  CONTROLLER_IMAGE: '{{joinPath .REGISTRY_BASE "aok-controller"}}'
  CONTROLLER_IMAGE_ID_PATH: '{{joinPath .SCRIPT_TMP_DIR "controller-image-id"}}'
  CRD_X_IMAGE: '{{joinPath .REGISTRY_BASE "crd-x"}}'

  KUBECONFIG: '{{joinPath .SCRIPT_TMP_DIR "kubeconfig"}}'
  SCHEMAS: '{{joinPath .GIT_ROOT "adventofcode/schema"}}'

  CHAINSAW_VERSION: v0.2.12

env:
  GIT_ROOT: '{{.GIT_ROOT}}'
  K3D_CLUSTER_NAME: '{{.K3D_CLUSTER_NAME}}'

tasks:
  default:
    # https://clig.dev/#help
    desc: Display a concise help text by default.
    silent: true
    cmd: task --list-all

  cluster-create:
    desc: Create a local k3s cluster with k3d, and import some images into it.
    requires:
      vars:
        - GIT_ROOT
        - K3D_CLUSTER_NAME
    preconditions:
      - sh: command -v docker
        msg: The 'docker' command is not installed or available on your PATH.
      - sh: command -v jq
        msg: The 'jq' command is not installed or available on your PATH.
      - sh: command -v k3d
        msg: The 'k3d' command is not installed or available on your PATH.
    status:
      - k3d cluster list --output=json | jq --exit-status '.[] | select(.name == "{{.K3D_CLUSTER_NAME}}")'
    cmd: '{{.GIT_ROOT}}/scripts/task.cluster-create.sh'

  cluster-await:
    desc: Wait for the local cluster to be ready.
    requires:
      vars:
        - GIT_ROOT
    deps:
      - task: cluster-create
    preconditions:
      - sh: command -v kubectl
        msg: The 'kubectl' command is not installed or available on your PATH.
    cmd: '{{.GIT_ROOT}}/scripts/task.cluster-await.sh'

  apply-crds:
    desc: Apply the CRDs to the cluster.
    requires:
      vars:
        - GIT_ROOT
        - K3D_CLUSTER_NAME
    deps:
      - task: cluster-await
    preconditions:
      - sh: command -v kubectl
        msg: The 'kubectl' command is not installed or available on your PATH.
    status:
      - kubectl --context="{{.KUBECTL_CONTEXT}}" diff --filename="{{.GIT_ROOT}}/adventofcode/config/crd/*.yaml"
    cmd: kubectl --context="{{.KUBECTL_CONTEXT}}" apply --filename="{{.GIT_ROOT}}/adventofcode/config/crd/*.yaml"

  controller-build:
    desc: Build the controller image.
    requires:
      vars:
        - CONTROLLER_IMAGE
        - CONTROLLER_IMAGE_ID_PATH
        - GIT_ROOT
    preconditions:
      - sh: command -v docker
        msg: The 'docker' command is not installed or available on your PATH.
    vars:
      CONTROLLER_IMAGE_ID: '{{.CONTROLLER_IMAGE}}:{{uuid}}'
    method: checksum
    sources:
      - '{{.GIT_ROOT}}/adventofcode/**/*'
      - exclude: '{{.GIT_ROOT}}/adventofcode/config/cluster/**/*.yaml'
    generates:
      - '{{.CONTROLLER_IMAGE_ID_PATH}}'
    dir: '{{.GIT_ROOT}}/adventofcode'
    cmds:
      - mkdir -p "{{osDir .CONTROLLER_IMAGE_ID_PATH}}"
      - docker build --tag "{{.CONTROLLER_IMAGE_ID}}" .
      - echo "{{.CONTROLLER_IMAGE_ID}}" > "{{.CONTROLLER_IMAGE_ID_PATH}}"

  controller-load:
    desc: Load the controller image into the local cluster.
    requires:
      vars:
        - CONTROLLER_IMAGE_ID_PATH
        - K3D_CLUSTER_NAME
        - KUBECTL_CONTEXT
    deps:
      - task: cluster-await
      - task: controller-build
    status:
      - >-
        docker exec "{{.KUBECTL_CONTEXT}}-server-0" crictl images --output=json
        | jq --arg CID "$(< "{{.CONTROLLER_IMAGE_ID_PATH}}")" --exit-status '[.images[].repoTags[]] | any(. == $CID)'
    cmd: k3d image import "$(< "{{.CONTROLLER_IMAGE_ID_PATH}}")" --cluster="{{.K3D_CLUSTER_NAME}}" --mode=auto

  controller-install:
    desc: Install the controller into the local cluster.
    requires:
      vars:
        - CONTROLLER_IMAGE_ID_PATH
        - GIT_ROOT
    deps:
      - task: controller-load
    cmds:
      - >-
        CID="$(< "{{.CONTROLLER_IMAGE_ID_PATH}}")"
        yq eval --inplace
        '(.spec.template.spec.containers[] | select(.name == "aok-controller") | .image) = strenv(CID)'
        "{{.GIT_ROOT}}/adventofcode/config/cluster/2-deployment/deployment.yaml"
      - for:
          - config/crd
          - config/cluster/0-namespace
          - config/cluster/1-rbac
          - config/cluster/2-deployment
        task: controller-install-internal
        vars:
          SPEC_DIR: '{{.ITEM}}'

  controller-install-internal:
    desc: Install the spec(s) in the given directory into the local cluster.
    internal: true
    run: when_changed
    requires:
      vars:
        - GIT_ROOT
        - KUBECTL_CONTEXT
        - SPEC_DIR
    status:
      - kubectl --context="{{.KUBECTL_CONTEXT}}" diff --filename="{{.GIT_ROOT}}/adventofcode/{{.SPEC_DIR}}/*.yaml"
    cmd: kubectl --context="{{.KUBECTL_CONTEXT}}" apply --filename="{{.GIT_ROOT}}/adventofcode/{{.SPEC_DIR}}/*.yaml"

  controller-bounce:
    desc: Restart the controller deployment in the local cluster.
    requires:
      vars:
        - KUBECTL_CONTEXT
    deps:
      - task: controller-install
    cmd: kubectl --context="{{.KUBECTL_CONTEXT}}" --namespace=aok-controller rollout restart deployment aok-controller

  crd-x-build:
    desc: Build the worker image.
    requires:
      vars:
        - CRD_X_IMAGE
        - GIT_ROOT
    preconditions:
      - sh: command -v docker
        msg: The 'docker' command is not installed or available on your PATH.
    method: checksum
    sources:
      - '{{.GIT_ROOT}}/crd-x/**/*'
    dir: '{{.GIT_ROOT}}/crd-x'
    cmd: docker build --tag "{{.CRD_X_IMAGE}}" .

  crd-x-kubeconfig:
    desc: Set up and transform a kubeconfig file with the K3D server address.
    requires:
      vars:
        - GIT_ROOT
        - K3D_CLUSTER_NAME
    vars:
      # This will be a container-to-container connection on the same network, using the 'docker run --network=...' flag.
      # The worker container can use the name of the control plane server container, and will be able to resolve its IP address.
      # The port is not the randomised port that Docker externalises, but that of the control plane itself inside the server container.
      # Thank you: https://rancher-users.slack.com/archives/CHM1EB3A7/p1745957501473809
      K3D_SERVER: https://{{.KUBECTL_CONTEXT}}-server-0:6443
    deps:
      - task: cluster-create
    preconditions:
      - sh: command -v kubectl
        msg: The 'kubectl' command is not installed or available on your PATH.
      - sh: command -v yq
        msg: The 'yq' command is not installed or available on your PATH.
    cmds:
      - mkdir -p "{{osDir .KUBECONFIG}}"
      - >-
        kubectl --context="{{.KUBECTL_CONTEXT}}" config view --minify --raw
        | yq ".clusters[].cluster.server = \"{{.K3D_SERVER}}\"" > "{{.KUBECONFIG}}"

  schema-update:
    desc: Update the JSON Schema files for Kinds in the adventofcode.jlucktay.dev Group, by passing the CRDs through the local cluster.
    requires:
      vars:
        - CRD_X_IMAGE
        - K3D_CLUSTER_NAME
        - KUBECONFIG
        - SCHEMAS
    deps:
      - task: apply-crds
      - task: crd-x-build
      - task: crd-x-kubeconfig
    preconditions:
      - sh: command -v docker
        msg: The 'docker' command is not installed or available on your PATH.
    cmds:
      - mkdir -p "{{.SCHEMAS}}"
      - >-
        docker run
        --network="{{.KUBECTL_CONTEXT}}"
        --rm
        --volume="{{.KUBECONFIG}}:/root/.kube/config:ro"
        --volume="{{.SCHEMAS}}:/schema/:rw"
        "{{.CRD_X_IMAGE}}"

  test:
    desc: Test the operator's functionality with Kyverno Chainsaw.
    requires:
      vars:
        - CHAINSAW_VERSION
        - KUBECONFIG
        - KUBECTL_CONTEXT
    deps:
      - task: apply-crds
      - task: crd-x-kubeconfig
    preconditions:
      - sh: command -v docker
        msg: The 'docker' command is not installed or available on your PATH.
    dir: '{{.GIT_ROOT}}/adventofcode/test'
    cmd: >-
      docker run
      --env=KUBECONFIG=/etc/kubeconfig/config
      --network="{{.KUBECTL_CONTEXT}}"
      --rm
      --volume={{.KUBECONFIG}}:/etc/kubeconfig/config
      --volume=${PWD}/:/chainsaw/
      ghcr.io/kyverno/chainsaw:{{.CHAINSAW_VERSION}}
      test /chainsaw
      --config /chainsaw/chainsaw-config.yaml

  down:
    desc: Tear down the local k3s cluster, remove any built images, and tidy up the temporary kubeconfig.
    deps:
      - task: down-cluster
      - task: down-docker
      - task: down-kubeconfig

  down-cluster:
    desc: Tear down the local k3s cluster.
    requires:
      vars:
        - GIT_ROOT
        - K3D_CLUSTER_NAME
    preconditions:
      - sh: command -v k3d
        msg: The 'k3d' command is not installed or available on your PATH.
    status:
      # Roll up the names of all k3d clusters and exit with zero if none of the cluster names match ours.
      - >-
        ! k3d cluster list --output=json
        | jq --exit-status '[.[] | isempty(select(.name == "{{.K3D_CLUSTER_NAME}}")) | not ] | any'
    cmd: k3d cluster delete --config="{{.GIT_ROOT}}/k3d-config.yaml"

  down-docker:
    desc: Remove any local built Docker images.
    requires:
      vars:
        - CONTROLLER_IMAGE
        - CONTROLLER_IMAGE_ID_PATH
    cmds:
      - >-
        docker images --filter=reference="{{.CONTROLLER_IMAGE}}" --no-trunc --quiet
        | sort --ignore-case --unique
        | xargs --max-args=1 docker rmi --force
      - rm -f "{{.CONTROLLER_IMAGE_ID_PATH}}"

  down-kubeconfig:
    desc: Tidy up the temporary kubeconfig.
    requires:
      vars:
        - KUBECONFIG
    status:
      - '! test -f {{.KUBECONFIG}}'
    cmd: rm -f "{{.KUBECONFIG}}"
